# 🗄️ 向量数据库指南

## 概述

LLMSider 的向量数据库支持在整个笔记库中进行语义搜索,使 AI 能够自动查找和使用相关信息。将其视为为您的 AI 提供笔记的照相记忆。

---

## 🎯 什么是向量搜索?

### 传统搜索 vs 向量搜索

**传统(关键词)搜索:**
```
查询: "人工智能应用"
匹配: 包含这些确切单词的笔记
```

**向量(语义)搜索:**
```
查询: "人工智能应用"
匹配: 关于以下内容的笔记:
  - 机器学习用例
  - 医疗保健中的 AI
  - 神经网络部署
  - 即使它们不包含确切的单词!
```

### 工作原理

```
1. 您的笔记 → 2. 分割成块 → 3. 转换为向量
   ┌─────────┐      ┌──────────┐        ┌───────────┐
   │ Note.md │ →    │ 块 1     │ →      │ [0.2, ... │
   │         │      │ 块 2     │        │ [0.5, ... │
   └─────────┘      └──────────┘        └───────────┘

4. 存储在数据库 ← 5. 使用 AI 查询 ← 6. 获取相关上下文
   ┌────────────┐      ┌──────────┐       ┌───────────┐
   │ 向量数据库 │ ←    │  查询    │  ←   │ AI 找到   │
   │ 已索引     │      │  向量    │       │ 相似的    │
   └────────────┘      └──────────┘       └───────────┘
```

---

## 🚀 设置指南

### 步骤 1: 启用向量数据库

1. **打开设置**
   - 设置 → LLMSider → 向量数据库

2. **启用向量数据库**
   - 切换"启用向量数据库"开关
   - 等待初始化

3. **配置嵌入模型**
   - 选择嵌入提供商:
     - **OpenAI** (text-embedding-3-small) - 推荐
     - **Hugging Face** (免费、本地)
     - **本地** (通过 Ollama)

### 步骤 2: 选择嵌入提供商

#### 选项 A: OpenAI(推荐)

**设置:**
1. 创建 OpenAI 连接(如果不存在)
2. 添加嵌入模型:
   ```yaml
   模型名称: text-embedding-3-small
   类型: 嵌入
   维度: 1536
   ```

**优点:**
- ✅ 高质量
- ✅ 快速
- ✅ 可靠
- ✅ 良好的成本/性能

**缺点:**
- ❌ 需要 API 密钥
- ❌ 数据发送到 OpenAI
- ❌ 每次嵌入有小额成本

#### 选项 B: Hugging Face(免费)

**设置:**
1. 创建 Hugging Face 连接
2. 添加嵌入模型:
   ```yaml
   模型: sentence-transformers/all-MiniLM-L6-v2
   类型: 嵌入
   维度: 384
   ```

**优点:**
- ✅ 免费
- ✅ 无需 API 密钥
- ✅ 隐私友好

**缺点:**
- ❌ 比 OpenAI 慢
- ❌ 较低质量
- ❌ 速率限制

#### 选项 C: 本地(Ollama)

**设置:**
1. 安装 Ollama
2. 拉取嵌入模型:
   ```bash
   ollama pull mxbai-embed-large
   ```
3. 配置 LLMSider:
   ```yaml
   连接: Ollama
   模型: mxbai-embed-large
   维度: 1024
   ```

**优点:**
- ✅ 免费
- ✅ 私密(本地)
- ✅ 无需 API
- ✅ 快速(配置良好的硬件)

**缺点:**
- ❌ 需要本地资源
- ❌ 设置复杂度

### 步骤 3: 配置索引

**分块策略:**
```yaml
策略: semantic  # 或: fixed, paragraph
块大小: 512     # 每块令牌数
重叠: 50         # 块之间的令牌重叠
```

**文件过滤器:**
```yaml
包含模式:
  - "**/*.md"       # 所有 Markdown 文件
  - "**/*.txt"      # 文本文件
  
排除模式:
  - "**/templates/**"  # 模板文件夹
  - "**/.obsidian/**"  # Obsidian 配置
```

### 步骤 4: 初始索引构建

1. 点击"重建索引"
2. 等待完成(显示进度)
3. 索引准备就绪!

**进度指示器:**
```
📊 正在索引笔记库...
─────────────────────────────── 45%
125 / 280 个文件已处理
```

---

## 🎨 功能

### 1. 自动上下文增强

**在设置中启用:**
```yaml
自动搜索: 已启用
最大结果: 3
相似度阈值: 0.7
```

**会发生什么:**
```
您: "我写了什么关于机器学习的内容?"
     ↓
向量数据库找到 3 个最相关的笔记
     ↓
AI 响应自动使用此上下文
```

### 2. 相似笔记发现

**查看相似笔记:**
- 侧边栏面板显示相关笔记
- 在您输入/导航时更新
- 点击打开

```
┌─────────────────────────────┐
│ 📊 相似笔记                 │
├─────────────────────────────┤
│ 🔗 ML 基础 (92%)            │
│ 🔗 神经网络 (87%)           │
│ 🔗 AI 伦理 (81%)            │
└─────────────────────────────┘
```

### 3. 相关文件建议

**在聊天期间:**
```
您: "告诉我关于生产力的内容"
AI: 💡 相关文件:
    - productivity-system.md
    - gtd-workflow.md
    - time-management.md
    
    您想让我包含这些吗?
```

### 4. 手动搜索

**命令面板:**
```
Cmd+P → "向量: 搜索笔记库"
```

**搜索结果:**
```markdown
查询: "项目管理"

结果:
1. 项目规划模板 (95%)
   预览: "...有效的项目管理需要..."
   
2. 敏捷方法 (89%)
   预览: "...使用敏捷管理项目..."
```

---

## ⚙️ 配置

### 分块策略

#### 1. 语义分块(推荐)
```yaml
策略: semantic
描述: 按含义/主题分割
最适合: 混合内容、自然笔记
```

#### 2. 固定大小分块
```yaml
策略: fixed
块大小: 512
重叠: 50
最适合: 一致的块大小
```

#### 3. 段落分块
```yaml
策略: paragraph
描述: 按段落分割
最适合: 结构良好的文档
```

### 性能设置

**索引:**
```yaml
批量大小: 10          # 一次处理的文件数
并行处理: 4           # 并发操作
速率限制: 100/分钟    # 每分钟 API 调用
```

**搜索:**
```yaml
最大结果: 5          # 每次查询的结果
最小相似度: 0.7     # 阈值(0-1)
缓存 TTL: 3600      # 缓存时间(秒)
```

---

## 📊 索引管理

### 同步索引

**增量同步:**
```
命令: "向量: 同步索引"
更新: 仅自上次同步以来更改的文件
速度: 快速(秒)
```

### 重建索引

**完全重建:**
```
命令: "向量: 重建索引"
更新: 所有文件
速度: 慢(分钟)
何时: 更改嵌入模型或块大小后
```

### 检查状态

**索引统计:**
```
总文件: 280
总块: 1,247
索引大小: 12.4 MB
上次同步: 5 分钟前
状态: 🟢 最新
```

---

## 💰 成本考虑

### 嵌入成本

**OpenAI 定价:**
```
text-embedding-3-small: $0.02 / 100万令牌

示例笔记库(1000 个笔记,50万字):
  ≈ 67万令牌
  成本: ~$0.013(一次性)
  
更新(每天 10 个笔记):
  ≈ 6.7K 令牌/天
  成本: ~$0.05/月
```

**Hugging Face:**
```
免费(有速率限制)
每月 10,000 次请求免费层
```

**本地(Ollama):**
```
免费(仅硬件成本)
无 API 成本
```

---

## 🐛 故障排除

### 索引构建问题

**问题: 索引构建失败**
```
错误: 无法嵌入文件: out-of-memory.md
```

**解决方案:**
1. ✅ 减小批量大小
2. ✅ 跳过大文件
3. ✅ 增加块大小
4. ✅ 检查嵌入模型

**问题: 索引慢**
```
进度: 10 个文件/分钟(预期: 50/分钟)
```

**解决方案:**
1. ✅ 增加并行处理
2. ✅ 使用更快的嵌入模型
3. ✅ 启用缓存
4. ✅ 排除不必要的文件

### 搜索问题

**问题: 未找到结果**
```
查询: "机器学习"
结果: 0 个匹配项
```

**解决方案:**
1. ✅ 降低相似度阈值
2. ✅ 尝试同义词
3. ✅ 检查文件是否已索引
4. ✅ 重建索引

---

## 📚 最佳实践

### 🎯 索引策略

1. **从小处开始**
   - 首先索引重要文件夹
   - 逐渐扩展
   - 监控性能

2. **定期同步**
   - 启用自动同步
   - 重大更改后同步
   - 每月完全重建

3. **质量胜于数量**
   - 排除低价值文件
   - 专注于参考材料
   - 保持笔记结构良好

### 🚀 搜索策略

1. **具体查询**
   ```
   ❌ "信息"
   ✅ "医疗保健中的机器学习应用"
   ```

2. **使用上下文**
   - 结合手动上下文
   - 交叉引用结果
   - 验证相关性

3. **迭代**
   - 从宽泛开始,细化
   - 尝试不同的措辞
   - 调整阈值

---

## 📖 相关指南

- [连接与模型](connections-and-models.md) - 嵌入设置
- [聊天界面](chat-interface.md) - 在聊天中使用向量搜索
- [设置指南](settings-guide.md) - 配置参考
- [故障排除](troubleshooting.md) - 常见问题

---

**需要帮助?** [GitHub Issues](https://github.com/llmsider/obsidian-llmsider/issues) | [Discord](https://discord.gg/llmsider)
