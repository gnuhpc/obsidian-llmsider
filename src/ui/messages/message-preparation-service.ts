/**
 * MessagePreparationService - è´Ÿè´£å‡†å¤‡å‘é€ç»™ LLM çš„æ¶ˆæ¯
 * 
 * èŒè´£ï¼š
 * - æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆç³»ç»Ÿæ¶ˆæ¯ + å†å²æ¶ˆæ¯ + ç”¨æˆ·æ¶ˆæ¯ï¼‰
 * - ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
 * - å¤„ç† Vector Search
 * - å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ã€æ–‡ä»¶ï¼‰
 * - Token ç®¡ç†å’Œæˆªæ–­
 */

import { ChatMessage, ChatSession } from '../../types';
import { Logger } from '../../utils/logger';
import type LLMSiderPlugin from '../../main';
import type { ContextManager } from '../../core/context-manager';
import type { ToolCoordinator } from '../tools/tool-coordinator';
import type { UIBuilder } from '../ui-builder';
import { TokenManager } from '../../utils/token-manager';
import { Notice } from 'obsidian';

export interface IMessagePreparationService {
	/**
	 * å‡†å¤‡è¦å‘é€ç»™ LLM çš„æ¶ˆæ¯åˆ—è¡¨
	 */
	prepareMessages(
		userMessage: ChatMessage,
		stepIndicatorsEl: HTMLElement | null,
		memoryContext: string,
		memoryMessages: ChatMessage[] | null,
		memoryEnabled: boolean
	): Promise<ChatMessage[]>;

	/**
	 * ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
	 */
	getSystemPrompt(memoryContext?: string): Promise<string>;

	/**
	 * æ›´æ–°æ­¥éª¤æŒ‡ç¤ºå™¨çŠ¶æ€
	 */
	updateStepIndicator(
		container: HTMLElement | null,
		stepName: string,
		state: 'pending' | 'active' | 'completed'
	): void;

	/**
	 * æ˜¾ç¤º Vector Search ç»“æœ
	 */
	displayVectorSearchResults(container: HTMLElement | null, results: any[]): void;

	/**
	 * è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜
	 */
	autoGenerateSessionTitle(userMessage: ChatMessage, assistantMessage: ChatMessage): Promise<void>;

	/**
	 * ä»å†…å®¹ä¸­æå–æœ€ç»ˆç­”æ¡ˆï¼ˆç§»é™¤æ€è€ƒè¿‡ç¨‹ï¼‰
	 */
	extractFinalAnswer(content: string): string;
}

export interface MessagePreparationCallbacks {
	getCurrentSession: () => ChatSession | null;
	updateStepIndicator: (
		container: HTMLElement | null,
		stepName: string,
		state: 'pending' | 'active' | 'completed'
	) => void;
	displayVectorSearchResults: (container: HTMLElement | null, results: any[]) => void;
	updateSession: (sessionId: string, updates: Partial<ChatSession>) => Promise<void>;
	updateSessionNameDisplay: (name: string) => void;
}

export class MessagePreparationService implements IMessagePreparationService {
	constructor(
		private plugin: LLMSiderPlugin,
		private contextManager: ContextManager,
		private toolCoordinator: ToolCoordinator,
		private uiBuilder: UIBuilder,
		private callbacks: MessagePreparationCallbacks
	) {}

	/**
	 * å‡†å¤‡è¦å‘é€ç»™ LLM çš„æ¶ˆæ¯åˆ—è¡¨
	 */
	async prepareMessages(
		userMessage: ChatMessage,
		stepIndicatorsEl: HTMLElement | null = null,
		memoryContext = '',
		memoryMessages: ChatMessage[] | null = null,
		memoryEnabled = false
	): Promise<ChatMessage[]> {
		const messages: ChatMessage[] = [];
		const hasContext = this.contextManager.hasContext();
		const includeExtrasWithContext = this.plugin.settings.contextSettings?.includeExtrasWithContext ?? false;
		const allowExtraContext = !hasContext || includeExtrasWithContext;

		// Add system message
		const systemPrompt = await this.getSystemPrompt(memoryContext);

		// Add local vector search context if auto-search is enabled
		// Skip during plugin initialization and session loading to prevent startup vector generation
		let vectorSearchContext = '';
		
		if (allowExtraContext && this.plugin.settings.vectorSettings.autoSearchEnabled && 
			this.plugin.state.isLoaded &&
			!this.plugin.state.isLoadingSession) {
			// Update step indicator to active
			this.updateStepIndicator(stepIndicatorsEl, 'vector-search', 'active');

			const vectorDBManager = this.plugin.getVectorDBManager();
			const isInitialized = vectorDBManager?.isSystemInitialized();
			
			if (vectorDBManager && isInitialized) {
				try {
					const status = vectorDBManager.getStatus();
					
					if (status.totalChunks > 0) {
						// Extract query from user message
						const query =
							typeof userMessage.content === 'string' ? userMessage.content : '';

						if (query) {
							Logger.debug('Performing local vector search for:', query);
							const results = await vectorDBManager.search(query);

							if (results.length > 0) {
								vectorSearchContext = `\n\n## Related Content from Your Vault\n\n${vectorDBManager.formatSearchResults(results)}`;

								// Log detailed information about each result
								Logger.debug(`Added ${results.length} vector search results to context:`);
								results.forEach((item, index) => {
									Logger.debug(`  [${index + 1}] File: ${item.filePath}`);
									Logger.debug(`      Score: ${(item.score * 100).toFixed(1)}%`);
									Logger.debug(
										`      Content preview: ${item.content.substring(0, 100)}...`
									);
								});

								// Log the formatted context that will be sent to LLM
								Logger.debug(
									'Formatted vector search context length:',
									vectorSearchContext.length,
									'chars'
								);
								Logger.debug(
									'Vector search context preview:',
									vectorSearchContext.substring(0, 500) + '...'
								);

								// Display search results summary in UI
								this.displayVectorSearchResults(stepIndicatorsEl, results);
							}
						}
					}
				} catch (error) {
					Logger.error('Vector search failed:', error);
				}
			}

			// Mark vector search as completed
			this.updateStepIndicator(stepIndicatorsEl, 'vector-search', 'completed');
		}

		const systemMessage: ChatMessage = {
			id: 'system-' + Date.now(),
			role: 'system',
			content: systemPrompt + vectorSearchContext,
			timestamp: Date.now()
		};

		// Add chat history: use Memory messages if available, no manual history fallback
		let chatHistory: ChatMessage[] = [];

		// Check if conversation history is enabled in settings
		if (allowExtraContext && this.plugin.settings.memorySettings.enableConversationHistory) {
			// Strategy: Try Memory first, then Local
			let usedMemoryHistory = false;
			const limit = this.plugin.settings.memorySettings.conversationHistoryLimit || 10;

			// 1. Try to use Memory-provided messages (if Memory is enabled and has data)
			if (memoryEnabled && memoryMessages && memoryMessages.length > 0) {
				chatHistory = memoryMessages;
				
				// Apply history limit to memory messages too
				if (chatHistory.length > limit) {
					chatHistory = chatHistory.slice(-limit);
					Logger.debug(`[Memory] ğŸ”„ Truncated Memory history to ${limit} messages`);
				}
				
				usedMemoryHistory = true;
				Logger.debug(
					'[Memory] ğŸ”„ Using Memory-managed history:',
					chatHistory.length,
					'messages'
				);
			}

			// 2. Fallback to Local Session messages (if Memory didn't provide history)
			if (!usedMemoryHistory) {
				const currentSession = this.callbacks.getCurrentSession();
				if (currentSession && currentSession.messages.length > 0) {
					// Exclude the current user message
					chatHistory = currentSession.messages.filter((m) => m.id !== userMessage.id);

					// Apply history limit
					if (chatHistory.length > limit) {
						chatHistory = chatHistory.slice(-limit);
					}

					if (chatHistory.length > 0) {
						Logger.debug(
							'[Memory] ğŸ“‚ Using local session history (Memory empty or disabled):',
							chatHistory.length,
							'messages'
						);
					} else {
						Logger.debug('[Memory] ğŸ“‚ Local history enabled but empty');
					}
				} else {
					Logger.debug('[Memory] ğŸ“‚ Local history enabled but no session messages');
				}
			}
		} else {
			// History is disabled
			chatHistory = [];
			Logger.debug('[Memory] ğŸ“‹ Conversation history disabled in settings');
		}

		// Prepare initial message list
		messages.push(systemMessage);
		messages.push(...chatHistory);

		// Handle multimodal content if present
		const imageData = this.contextManager.getImageDataForMultimodal();
		let finalUserMessage = userMessage;

		// æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ Free Qwen provider
		const provider = this.plugin.getActiveProvider();
		const isFreeQwen = provider?.getProviderName() === 'free-qwen';

		// Process images if present
		if (imageData.length > 0) {
			const supportsVision = provider?.supportsVision();
			Logger.debug('[MessagePrep] Provider vision support check:', {
				model: provider?.getModelName(),
				supportsVision,
				providerType: provider?.getProviderName()
			});

			if (!supportsVision) {
				// Show notice instead of throwing error
				const modelName = provider?.getModelName() || 'Current model';
				new Notice(
					`âš ï¸ ${modelName} ä¸æ”¯æŒå›¾ç‰‡åˆ†æï¼Œå·²è·³è¿‡ ${imageData.length} å¼ å›¾ç‰‡ï¼Œä»…å¤„ç†æ–‡å­—å†…å®¹`,
					6000
				);
				Logger.warn('Model does not support vision, skipping images:', {
					model: modelName,
					imageCount: imageData.length
				});

				// Clear image data from context manager to prevent retry
				this.contextManager.clearImageData();

				// Continue with text-only message (don't add multimodal content)
			} else {
				// Create multimodal content with images
				const multimodalContent: unknown[] = [];
				if (userMessage.content && typeof userMessage.content === 'string') {
					multimodalContent.push({ type: 'text', text: userMessage.content });
				}

				// æ·»åŠ å›¾ç‰‡
				imageData.forEach((image) => {
					multimodalContent.push({
						type: 'image',
						source: {
							type: 'base64',
							media_type: image.mediaType,
							data: image.base64
						}
					});
				});

				finalUserMessage = { ...userMessage, content: multimodalContent as any };
			}
		}

		// Free Qwen: æ·»åŠ æ–‡ä»¶å¼•ç”¨ï¼ˆç‹¬ç«‹äºå›¾ç‰‡å¤„ç†ï¼‰
		if (isFreeQwen) {
			const fileData = await this.contextManager.getFileDataForRemoteParsing();
			if (fileData.length > 0) {
				Logger.debug(
					`[FreeQwen] Adding ${fileData.length} file(s) for remote parsing`
				);

				// å¦‚æœå·²ç»æœ‰ multimodal contentï¼ˆæ¥è‡ªå›¾ç‰‡ï¼‰ï¼Œç»§ç»­æ·»åŠ ï¼›å¦åˆ™åˆ›å»ºæ–°çš„
				let multimodalContent: unknown[];
				if (Array.isArray(finalUserMessage.content)) {
					multimodalContent = finalUserMessage.content as unknown[];
				} else {
					multimodalContent = [];
					if (finalUserMessage.content && typeof finalUserMessage.content === 'string') {
						multimodalContent.push({ type: 'text', text: finalUserMessage.content });
					}
				}

				fileData.forEach((file) => {
					// å°†æ–‡ä»¶è½¬æ¢ä¸º base64 data URL
					const bytes = new Uint8Array(file.buffer);
					let binary = '';
					for (let i = 0; i < bytes.byteLength; i++) {
						binary += String.fromCharCode(bytes[i]);
					}
					const base64 = btoa(binary);
					const dataUrl = `data:${file.mimeType};base64,${base64}`;

					multimodalContent.push({
						type: 'file',
						file_url: {
							url: dataUrl
						}
					});
				});

				finalUserMessage = { ...userMessage, content: multimodalContent as any };
			}
		}

		messages.push(finalUserMessage);

		// Apply token management - this will truncate if needed
		const contextPrompt = systemPrompt;

		// Get available tools for token estimation (only in Agent conversation mode)
		const conversationMode = this.plugin.settings.conversationMode || 'normal';
		let availableTools: any[] = [];
		if (conversationMode === 'agent') {
			try {
				const toolManager = this.plugin.getToolManager();
				if (toolManager) {
					availableTools = await toolManager.getAllTools();
				}
			} catch (error) {
				Logger.warn('Failed to get tools for token estimation:', error);
			}
		}

		// Get current model name for model-specific token limits (reuse provider from above)
		const modelName = provider?.getModelName();

		// Check if token limit is exceeded and handle it
		if (
			TokenManager.isTokenLimitExceeded(
				messages,
				contextPrompt,
				availableTools,
				modelName
			)
		) {
			Logger.warn('Token limit exceeded, applying token management', {
				model: modelName,
				limit: modelName
					? TokenManager.getModelTokenLimit(modelName)
					: TokenManager.MAX_CONTEXT_TOKENS
			});

			// Show warning to user
			new Notice(
				this.plugin.getI18nManager()?.t('notifications.ui.tokenLimitExceeded') ||
					'Token limit exceeded. Truncating conversation history to fit within limits.',
				5000
			);

			// Get truncated messages (this will preserve the most recent messages and user input)
			const truncatedMessages = TokenManager.truncateMessagesToFitTokens(
				messages,
				contextPrompt,
				availableTools,
				modelName
			);

			// Log the truncation for debugging
			Logger.debug('Message truncation applied:', {
				originalCount: messages.length,
				truncatedCount: truncatedMessages.length,
				originalTokens: TokenManager.estimateTokensForMessages(messages),
				truncatedTokens: TokenManager.estimateTokensForMessages(truncatedMessages)
			});

			return truncatedMessages;
		}

		// Log token usage for monitoring
		const totalTokens =
			TokenManager.estimateTokensForMessages(messages) +
			TokenManager.estimateTokensForContext(contextPrompt) +
			TokenManager.estimateTokensForTools(availableTools);
		const effectiveLimit = modelName
			? TokenManager.getModelTokenLimit(modelName)
			: TokenManager.MAX_CONTEXT_TOKENS;

		Logger.debug('Token usage:', {
			totalTokens: TokenManager.formatTokenUsage(totalTokens),
			warningLevel: TokenManager.getTokenWarningLevel(totalTokens),
			messageCount: messages.length,
			model: modelName,
			effectiveLimit
		});

		// Show warning if approaching limits
		const warningLevel = TokenManager.getTokenWarningLevel(totalTokens);
		if (warningLevel === 'warning') {
			new Notice(
				this.plugin.getI18nManager()?.t('notifications.ui.approachingTokenLimit') ||
					'Approaching token limit. Consider starting a new chat if you encounter issues.',
				4000
			);
		}
		return messages;
	}

	/**
	 * ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
	 */
	async getSystemPrompt(memoryContext = ''): Promise<string> {
		const basePrompt = `You are an AI assistant integrated into Obsidian, a note-taking app.`;

		// Check if working memory is enabled in settings
		const workingMemoryEnabled = this.plugin.settings.memorySettings.enableWorkingMemory;

		// Add working memory context and protocol only if working memory is enabled
		let memorySection = '';
		if (workingMemoryEnabled) {
			if (memoryContext) {
				// Has existing working memory context
				memorySection = `\n\n## User Information (Working Memory)\n\nYou have access to important information about this user that you should remember and reference when relevant. This information persists across ALL conversations:\n\n${memoryContext}\n\n**CRITICAL - Memory Update Protocol:**\nWhen the user shares personal information (name, preferences, interests, location, etc.), you MUST append a hidden memory update marker at the END of your response, AFTER all user-visible content. Format:\n\n[MEMORY_UPDATE]\n- Name: [user's name]\n- Location: [user's location]\n- Preferences: [any preferences]\n[/MEMORY_UPDATE]\n\n**IMPORTANT**: This marker will be automatically hidden from the user - do NOT explain or mention it in your visible response!\n`;
			} else {
				// No existing working memory, but feature is enabled
				memorySection = `\n\n## User Information (Working Memory)\n\n**CRITICAL - Memory Update Protocol:**\nWhen the user shares personal information (name, preferences, interests, location, etc.), you MUST append a hidden memory update marker at the END of your response, AFTER all user-visible content. Format:\n\n[MEMORY_UPDATE]\n- Name: [user's name]\n- Location: [user's location]\n- Preferences: [any preferences]\n[/MEMORY_UPDATE]\n\n**IMPORTANT**: This marker will be automatically hidden from the user - do NOT explain or mention it in your visible response! Just respond naturally to the user, then add the marker at the end.\n`;
			}
		}
		// If working memory is disabled, memorySection remains empty (no memory protocol)

		const directoryBestPractices = `

CRITICAL: Content First, Operations Last
When creating or modifying notes:
1. **FOCUS ON CONTENT FIRST**: Ask about what the user wants (structure, format, fields)
2. Generate/show the content for user review and confirmation
3. **ONLY AFTER content is confirmed**, then handle file operations:
   - If user wants to check directories/files: call list_directory({directoryPath: ""}) - this is READ-ONLY, no creation
   - Present directory options to user
   - Wait for user to choose location
   - Then create/modify the file with create() tool

IMPORTANT: list_directory is for VIEWING ONLY - it shows both folders AND files but does NOT create anything!
Only use create() tool to actually create files/folders.

**CRITICAL: ALWAYS Reuse Existing Directories - Creating New Directories is RARE!**
- When list_directory shows existing directories and files, you MUST STRONGLY prefer reusing existing directories
- **Default behavior: Use existing directories** - Creating new directories should be the EXCEPTION, not the norm
- **ABSOLUTE RULE: Use EXACT directory names from list_directory result - NO modifications allowed!**
  * âœ… If listing shows "Template", use "Template/" (exact match)
  * âœ… If listing shows "æ¨¡æ¿", use "æ¨¡æ¿/" (exact Chinese name)
  * âœ… If listing shows "Book", use "Book/" (capital B matches listing)
  * âœ— If listing shows "Template", DO NOT use "Templates/" (different name!)
  * âœ— If listing shows "æ¨¡æ¿", DO NOT use "Template/" (translation not allowed!)
  * âœ— DO NOT change case: "Book" â‰  "book", "Template" â‰  "template"
  * âœ— DO NOT pluralize/singularize existing names
- Before even THINKING about "æ–°å»ºç›®å½•", thoroughly check if an existing directory can work:
  * Consider semantic similarity: "æ—¥è®°" can use "Daily/", "å·¥ä½œ" can use "Work/" or "Projects/"
  * But always use the EXACT name from the listing!
- **ONLY suggest "æ–°å»ºç›®å½•" if ALL of these are true:**
  1. User EXPLICITLY asked to create a new directory/folder in their request, OR
  2. NO existing directory is semantically suitable for the content type, AND
  3. The content represents a genuinely new category not covered by existing directories
- When checking for similar directories, understand semantic similarity but ALWAYS use exact names:
  * "Template" and "æ¨¡æ¿" both mean templates - use whichever exists (exact name!)
  * "Book" and "book" are the same semantically but use the exact case from listing
- Note: list_directory returns BOTH folders and files, so you can see the full directory structure

**PRIORITY ORDER when presenting options:**
1. Most relevant existing directory with EXACT name (explain why it fits)
2. Second relevant existing directory with EXACT name (if applicable)
3. ONLY if truly necessary: "æ–°å»ºç›®å½•" (explain why existing ones don't work)

Example workflow:
User: "Create a reading template"
Step 1: Ask about template structure/content (NOT about filename or location!)
Step 2: Generate and show the template content
Step 3: After user confirms content is good
Step 4: If needed, call list_directory({directoryPath: ""}) to show existing directories and files
Step 5: Check listing result shows: ["Template", "æ¨¡æ¿", "Book", "Daily"]
   - Analyze and ask: "ä¿å­˜åˆ°å“ªé‡Œï¼ŸTemplate/ (é€‚åˆæ¨¡æ¿) / æ¨¡æ¿/ (ä¸­æ–‡æ¨¡æ¿ç›®å½•) / Book/ (é€‚åˆè¯»ä¹¦ç›¸å…³)"
   - Use EXACT names: "Template" not "Templates", "æ¨¡æ¿" not "Template"
   - DO NOT automatically include "æ–°å»ºç›®å½•" unless user asked for it or no directory fits
Step 6: After user chooses, MUST call create({path: "ChosenDirectory/filename.md", content: "..."})
   - If user chose "Template", path must be "Template/filename.md" (exact match!)
Step 7: Wait for create() tool result before concluding

**After calling list_directory, you MUST continue with asking user for location and then call create()!**
**DO NOT stop after listing directories/files - that's just step 4, you need to finish steps 5-6!**
**File operations (where to save, what to name) come LAST, after content is ready!**`;

		const conversationMode = this.plugin.settings.conversationMode || 'normal';
		let modePrompt = '';

		if (conversationMode === 'agent') {
			// Agent mode: use plan-execute system with tools
			modePrompt = `You're in Agent mode - you have access to various tools and should use the plan-execute framework for complex tasks.

CRITICAL: You MUST use the available tools. Do not just describe what you would do - actually call the tools!

For weather queries about New Mexico:
1. IMMEDIATELY call get-forecast tool with location "Albuquerque, NM"
2. IMMEDIATELY call get-alerts tool with location "New Mexico"
3. Only after getting the data, provide your response

DO NOT say "I will get data" - ACTUALLY GET THE DATA by calling the tools first!

IMPORTANT: When users ask about "latest", "recent", "current", or time-sensitive information:
1. FIRST call the get_current_date tool to get the current date
2. Use this date information to provide accurate, time-aware responses
3. For example: "latest news", "recent updates", "what's new", "ä»Šå¤©", "æœ€æ–°çš„", etc.

CRITICAL: Avoid Redundant Web Content Fetching
**Before fetching web page content, ALWAYS check conversation history first:**
1. **Check if the URL has been fetched before** in this conversation
2. **If the URL appears in previous messages with content**, DO NOT fetch it again
3. **Reuse the previously fetched content** from conversation history
4. **Only fetch if:**
   - The URL has never been fetched in this conversation, OR
   - Previous fetch failed or returned incomplete data, OR
   - User explicitly asks to refresh/refetch the content
5. **Look for these indicators in conversation history:**
   - Tool execution results from fetch_web_content, fetch_url, or similar tools
   - Messages containing "Successfully fetched content from [URL]"
   - Previous responses that include content from the URL
6. **Example - DO NOT DO THIS:**
   Message 1: [fetch_web_content called for https://example.com, got content]
   Message 3: User asks follow-up question about the article
   You: [fetch_web_content for https://example.com again] â† WRONG! Content already available!
7. **Example - CORRECT behavior:**
   Message 1: [fetch_web_content called for https://example.com, got content]
   Message 3: User asks follow-up question
   You: [Use the content from Message 1 to answer] â† CORRECT!

**Remember: Web fetching takes time and resources - avoid redundant fetches by checking history first!**

The tools are real and functional - you must use them!
${directoryBestPractices}

IMPORTANT RESPONSE STYLE:
- Always provide direct answers without preamble, introductions, or meta-commentary
- Do NOT start responses with phrases like "æˆ‘æ¥å¸®ä½ ...", "æˆ‘å°†ä¸ºä½ ...", "è®©æˆ‘..." etc.
- Do NOT end with summaries, suggestions for further action, or closing remarks
- For any task (writing, expanding, modifying, explaining), output the actual result immediately
- Avoid unnecessary framing language - just deliver the requested content directly`;
		} else {
			// Basic Q&A mode: provide helpful responses with action buttons
			modePrompt = `You're in basic Q&A mode - provide helpful, informative responses to user questions. When the user references files or provides context, make sure to use that information to provide relevant answers.

If the user asks you to modify or work with files mentioned in the context, provide specific suggestions or show what the modified content should look like.
${directoryBestPractices}

IMPORTANT RESPONSE STYLE:
- Always provide direct answers without preamble, introductions, or meta-commentary
- Do NOT start responses with phrases like "æˆ‘æ¥å¸®ä½ ...", "æˆ‘å°†ä¸ºä½ ...", "è®©æˆ‘..." etc.
- Do NOT end with summaries, suggestions for further action, or closing remarks
- For any task (writing, expanding, modifying, explaining), output the actual result immediately
- Avoid unnecessary framing language - just deliver the requested content directly`;
		}

		// Get available tools and add them to the system prompt
		const toolsInfo = await this.toolCoordinator.getAvailableToolsInfo();

		// Add context from ContextManager (will auto-refresh file contents)
		// Pass model name to ensure proper token limits for file extraction
		const provider = this.plugin.getActiveProvider();
		const modelName = provider?.getModelName();
		const providerName = provider?.getProviderName();
		const isFreeQwen = providerName === 'free-qwen';
		// For Free Qwen, skip file content in context prompt (files are sent in user message)
		const contextPrompt = await this.contextManager.generateContextPrompt(
			undefined,
			modelName,
			isFreeQwen,
			providerName
		);

		return `${basePrompt}
${memorySection}
${modePrompt}

${toolsInfo}

Context Information:
${contextPrompt}

Remember: Always respond to the user. If you use tools, explain what you're doing. If you can't use tools, explain what you would do with them.`;
	}

	/**
	 * æ›´æ–°æ­¥éª¤æŒ‡ç¤ºå™¨çŠ¶æ€ï¼ˆå§”æ‰˜ç»™å›è°ƒï¼‰
	 */
	updateStepIndicator(
		container: HTMLElement | null,
		stepName: string,
		state: 'pending' | 'active' | 'completed'
	): void {
		this.callbacks.updateStepIndicator(container, stepName, state);
	}

	/**
	 * æ˜¾ç¤º Vector Search ç»“æœï¼ˆå§”æ‰˜ç»™å›è°ƒï¼‰
	 */
	displayVectorSearchResults(container: HTMLElement | null, results: any[]): void {
		this.callbacks.displayVectorSearchResults(container, results);
	}

	/**
	 * è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜ï¼ˆåœ¨é¦–è½®å¯¹è¯åï¼‰
	 */
	async autoGenerateSessionTitle(
		userMessage: ChatMessage,
		assistantMessage: ChatMessage
	): Promise<void> {
		const currentSession = this.callbacks.getCurrentSession();
		if (!currentSession) {
			Logger.debug('[TitleGen] No current session, skipping');
			return;
		}

		// Count only user and assistant messages, excluding system messages, tool messages, etc.
		const conversationMessages = currentSession.messages.filter(
			(m) => m.role === 'user' || m.role === 'assistant'
		);

		Logger.debug('[TitleGen] Session name:', currentSession.name);
		Logger.debug('[TitleGen] Conversation messages count:', conversationMessages.length);
		Logger.debug('[TitleGen] Total messages count:', currentSession.messages.length);
		Logger.debug(
			'[TitleGen] Message roles:',
			currentSession.messages.map((m) => m.role).join(', ')
		);

		// Only generate title after first round (2 messages: 1 user + 1 assistant)
		if (conversationMessages.length === 2 && currentSession.name === 'Untitled') {
			// Run title generation in background without blocking
			const sessionId = currentSession.id;

			// Don't await - let it run in background
			(async () => {
				try {
					const userContent =
						typeof userMessage.content === 'string'
							? userMessage.content
							: JSON.stringify(userMessage.content);
					let assistantContent =
						typeof assistantMessage.content === 'string'
							? assistantMessage.content
							: JSON.stringify(assistantMessage.content);

					// Extract final answer by removing thinking sections
					assistantContent = this.extractFinalAnswer(assistantContent);

					Logger.debug('[TitleGen] ğŸ¬ Starting title generation in background...');
					Logger.debug('[TitleGen] User content length:', userContent.length);
					Logger.debug(
						'[TitleGen] Assistant content length (after removing thinking):',
						assistantContent.length
					);

					const sessionName = await this.uiBuilder.generateSessionNameFromMessage(
						userContent,
						assistantContent
					);

					Logger.debug('[TitleGen] âœ“ Generated title:', sessionName);

					// Update session title
					await this.callbacks.updateSession(sessionId, { name: sessionName });
					const updatedSession = this.callbacks.getCurrentSession();
					if (updatedSession && updatedSession.id === sessionId) {
						updatedSession.name = sessionName;
						this.callbacks.updateSessionNameDisplay(sessionName);
						Logger.debug('[TitleGen] âœ“ Session title updated in UI');
					} else {
						Logger.debug('[TitleGen] âš ï¸ Session changed, not updating UI');
					}
				} catch (error) {
					Logger.error('[TitleGen] âŒ Failed to auto-generate session title:', error);
				}
			})();
		}
	}

	/**
	 * ä»å†…å®¹ä¸­æå–æœ€ç»ˆç­”æ¡ˆï¼ˆç§»é™¤æ€è€ƒè¿‡ç¨‹ï¼‰
	 * ç”¨äºæ ‡é¢˜ç”Ÿæˆï¼Œè·³è¿‡æ€è€ƒè¿‡ç¨‹
	 */
	extractFinalAnswer(content: string): string {
		// Remove thinking callout sections (e.g., "> [!tip] æ€è€ƒè¿‡ç¨‹\n> ...")
		let cleaned = content;

		// Pattern 1: Remove callout blocks with thinking content
		// Matches: > [!tip] æ€è€ƒè¿‡ç¨‹\n> content\n> more content\n\n
		cleaned = cleaned.replace(/^>\s*\[!\w+\][^\n]*æ€è€ƒ[^\n]*\n(>\s*[^\n]*\n)*\n*/gm, '');

		// Pattern 2: Remove any remaining > quoted blocks at the start
		cleaned = cleaned.replace(/^(>\s*[^\n]*\n)+\n*/m, '');

		return cleaned.trim();
	}
}
